{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare accuracy of CNN with BCE loss function and CNN with advanced BCE loss function on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 16\n",
    "LR = 0.001\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    TARGET = 'cuda'\n",
    "else:\n",
    "    TARGET = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train and test MNIST datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = torchvision.datasets.MNIST('', train=True, download=True,\n",
    "                       transform=torchvision.transforms.Compose([\n",
    "                           torchvision.transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = torchvision.datasets.MNIST('', train=False, download=True,\n",
    "                       transform=torchvision.transforms.Compose([\n",
    "                           torchvision.transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (input - [batch_size, 1, 28, 28], output [batch_size, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, 5)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(4*4*64, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.conv1(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, (2, 2))\n",
    "        \n",
    "        x = torch.nn.functional.relu(self.conv2(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, (2, 2))\n",
    "        \n",
    "        x = x.view(-1, 4*4*64) # flattrern\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "print(Net())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(TARGET)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "bce_loss = torch.nn.BCELoss()\n",
    "\n",
    "best_net = Net().to(TARGET)\n",
    "best_loss = torch.tensor(10e10)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    time.sleep(1)\n",
    "    for data in tqdm(train_dataloader): \n",
    "        x_train, y_train = data\n",
    "        x_train /= 255.0\n",
    "        \n",
    "        x_train = x_train.to(TARGET)\n",
    "        y_train = y_train.to(TARGET)\n",
    "    \n",
    "        net.zero_grad() \n",
    "        output = net(x_train)\n",
    "        \n",
    "        y_train_ans = torch.zeros(output.size()).float().to(TARGET)\n",
    "        for i in range(y_train.size()[0]):\n",
    "            y_train_ans[i, y_train[i]] = 1\n",
    "        \n",
    "        loss = bce_loss(output, y_train_ans)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('Loss', loss.item())\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_net = copy.deepcopy(net)\n",
    "        best_loss = loss\n",
    "\n",
    "time.sleep(0.1)\n",
    "print('Best loss', best_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(test))\n",
    "print('Item', i)\n",
    "\n",
    "net_result = best_net(test[i][0].unsqueeze(0).to(TARGET))\n",
    "real = test[i][1]\n",
    "\n",
    "print('Predict', np.argmax(net_result.cpu().detach().numpy()))\n",
    "print('Real', real)\n",
    "\n",
    "plt.imshow(test[i][0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN train with advanced loss calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_adv = Net().to(TARGET)\n",
    "optimizer_adv = torch.optim.Adam(net_adv.parameters(), lr=LR)\n",
    "bce_loss_adv = torch.nn.BCELoss()\n",
    "\n",
    "best_net_adv = Net().to(TARGET)\n",
    "best_loss_adv = torch.tensor(10e10)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    time.sleep(1)\n",
    "    for data in tqdm(train_dataloader): \n",
    "        x_train, y_train = data\n",
    "        x_train /= 255.0\n",
    "        \n",
    "        x_train = x_train.cuda()\n",
    "        y_train = y_train.cuda()\n",
    "    \n",
    "        net_adv.zero_grad() \n",
    "        output = net_adv(x_train)\n",
    "    \n",
    "        y_train_ans = torch.zeros(output.size()).float().to(TARGET)\n",
    "        obj = torch.zeros(output.size()).bool().to(TARGET)\n",
    "        no_obj = torch.zeros(output.size()).fill_(1).bool().to(TARGET)\n",
    "        \n",
    "        for i in range(y_train.size()[0]):\n",
    "            obj[i, y_train[i]] = 1\n",
    "            y_train_ans[i, y_train[i]] = 1\n",
    "            \n",
    "        for i in range(y_train.size()[0]):\n",
    "            no_obj[i, y_train[i]] = 0\n",
    "        \n",
    "        loss_obj = bce_loss_adv(output[obj], y_train_ans[obj])\n",
    "        loss_no_obj = bce_loss_adv(output[no_obj], y_train_ans[no_obj])\n",
    "        loss_adv = 1.0 * loss_obj + 3.0 * loss_no_obj\n",
    "        \n",
    "        loss_adv.backward()\n",
    "        optimizer_adv.step()\n",
    "    \n",
    "    print('Loss', loss_adv.item())\n",
    "    \n",
    "    if loss_adv < best_loss_adv:\n",
    "        best_net_adv = copy.deepcopy(net_adv)\n",
    "        best_loss_adv = loss_adv\n",
    "\n",
    "time.sleep(0.1)\n",
    "print('Best loss', best_loss_adv.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(test))\n",
    "print('Item', i)\n",
    "\n",
    "adv_net_result = best_net_adv(test[i][0].unsqueeze(0).to(TARGET))\n",
    "real = test[i][1]\n",
    "\n",
    "print('Predict', np.argmax(adv_net_result.cpu().detach().numpy()))\n",
    "print('Real', real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(test))\n",
    "print('Item', i)\n",
    "\n",
    "net_result = best_net(test[i][0].unsqueeze(0).to(TARGET))\n",
    "adv_net_result = best_net_adv(test[i][0].unsqueeze(0).to(TARGET))\n",
    "real = test[i][1]\n",
    "\n",
    "print('Predict', np.argmax(net_result.cpu().detach().numpy()))\n",
    "print('Predict (adv loss)', np.argmax(adv_net_result.cpu().detach().numpy()))\n",
    "print('Real', real)\n",
    "\n",
    "plt.imshow(test[i][0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of errors for every network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_wr = 0\n",
    "adv_net_wr = 0\n",
    "\n",
    "for t_data in tqdm(test):\n",
    "    net_result = best_net(t_data[0].unsqueeze(0).to(TARGET))\n",
    "    adv_net_result = best_net_adv(t_data[0].unsqueeze(0).to(TARGET))\n",
    "    \n",
    "    net_result = np.argmax(net_result.cpu().detach().numpy())\n",
    "    adv_net_result = np.argmax(adv_net_result.cpu().detach().numpy())\n",
    "    \n",
    "    if net_result != t_data[1]:\n",
    "        net_wr += 1\n",
    "    \n",
    "    if adv_net_result != t_data[1]:\n",
    "        adv_net_wr += 1\n",
    "\n",
    "time.sleep(0.1)\n",
    "print('Predict errors', net_wr)\n",
    "print('Predict errors (adv loss)', adv_net_wr)\n",
    "\n",
    "print('Accuracy', (1 - float(net_wr / len(test))) * 100)\n",
    "print('Accuracy (adv loss)', (1 - float(adv_net_wr / len(test))) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
