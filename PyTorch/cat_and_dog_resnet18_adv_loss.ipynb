{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare accuracy of ResNet18 CNN with BCE loss function and CNN with advanced BCE loss function on Kaggle Cat-Dog dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "LR = 0.001\n",
    "LABELS = ['Cat', 'Dog']\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    TARGET = 'cuda'\n",
    "else:\n",
    "    TARGET = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes for load Cat-Dog dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDog():\n",
    "    def __init__(self, path):\n",
    "        self.img_size = 100\n",
    "    \n",
    "        self.train_data = []\n",
    "        self.cat_path = os.path.normpath(path) + '/Cat'\n",
    "        self.dog_path = os.path.normpath(path) + '/Dog'\n",
    "        \n",
    "        self.labels = {self.cat_path: 0, self.dog_path: 1}\n",
    "    \n",
    "    def get_train_data(self):\n",
    "        for label in self.labels:\n",
    "            images_path = glob.glob(label + '/*.jpg')\n",
    "            images_path.sort()\n",
    "            \n",
    "            for image_path in tqdm(images_path):\n",
    "                try:\n",
    "                    img = cv2.imread(image_path)\n",
    "                    img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "                    \n",
    "                    img = Image.fromarray(img)\n",
    "                    img = torchvision.transforms.ToTensor()(img)\n",
    "                    \n",
    "                    ans = np.eye(2)[self.labels[label]]\n",
    "                    ans = torch.tensor(ans, dtype=torch.float32)\n",
    "                    \n",
    "                    self.train_data.append([img, ans])\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        return self.train_data\n",
    "\n",
    "class CatDogDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.__data = data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.__data[index][0], self.__data[index][1])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.__data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset and split to \"train\" and \"test\" datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dog = CatDog(path='PetImages/')\n",
    "cat_dog_dataset = cat_dog.get_train_data()\n",
    "\n",
    "np.random.shuffle(cat_dog_dataset)\n",
    "print('Dataset length', len(cat_dog_dataset))\n",
    "\n",
    "cat_dog_train = cat_dog_dataset[:int(len(cat_dog_dataset) * 0.8)]\n",
    "cat_dog_test = cat_dog_dataset[int(len(cat_dog_dataset) * 0.8):]\n",
    "\n",
    "print('Train length', len(cat_dog_train))\n",
    "print('Test length', len(cat_dog_test))\n",
    "\n",
    "train = CatDogDataset(cat_dog_train)\n",
    "test = CatDogDataset(cat_dog_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchvision.models.resnet18(pretrained=False, num_classes=2).to(TARGET)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "best_net = torchvision.models.resnet18(pretrained=False, num_classes=2).to(TARGET)\n",
    "best_loss = torch.tensor(10e10)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    time.sleep(1)\n",
    "    for data in tqdm(train_dataloader): \n",
    "        x_train, y_train = data\n",
    "        x_train /= 255.0\n",
    "        \n",
    "        x_train = x_train.to(TARGET)\n",
    "        y_train = y_train.to(TARGET)\n",
    "    \n",
    "#         net.zero_grad() \n",
    "        optimizer.zero_grad() \n",
    "        output = net(x_train)\n",
    "        \n",
    "        loss = mse_loss(output, y_train)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('Loss', loss.item())\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_net = copy.deepcopy(net)\n",
    "        best_loss = loss\n",
    "\n",
    "time.sleep(0.1)\n",
    "print('Best loss', best_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(test) - 1)\n",
    "print('Item', i)\n",
    "\n",
    "net_result = best_net(test[i][0].unsqueeze(0).to(TARGET))\n",
    "real = test[i][1]\n",
    "\n",
    "p = np.argmax(net_result.cpu().detach().numpy())\n",
    "r = np.argmax(real.detach().numpy())\n",
    "\n",
    "print('Predict:', LABELS[p])\n",
    "print('Real:', LABELS[r])\n",
    "\n",
    "img = np.array(test[i][0].permute(1, 2, 0))\n",
    "img = img[:, :, ::-1].copy()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN train with advanced loss calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_adv = torchvision.models.resnet18(pretrained=False, num_classes=2).to(TARGET)\n",
    "optimizer_adv = torch.optim.Adam(net_adv.parameters(), lr=LR)\n",
    "mse_loss_adv = torch.nn.MSELoss()\n",
    "\n",
    "best_net_adv = torchvision.models.resnet18(pretrained=False, num_classes=2).to(TARGET)\n",
    "best_loss_adv = torch.tensor(10e10)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    time.sleep(1)\n",
    "    for data in tqdm(train_dataloader): \n",
    "        x_train, y_train = data\n",
    "        x_train /= 255.0\n",
    "        \n",
    "        x_train = x_train.to(TARGET)\n",
    "        y_train = y_train.to(TARGET)\n",
    "    \n",
    "        optimizer_adv.zero_grad() \n",
    "#         net_adv.zero_grad() \n",
    "        output = net_adv(x_train)\n",
    "    \n",
    "        obj = torch.zeros(output.size()).bool().to(TARGET)\n",
    "        no_obj = torch.zeros(output.size()).fill_(1).bool().to(TARGET)\n",
    "        \n",
    "        for i in range(y_train.size()[0]):\n",
    "            pos = np.argmax(y_train[i].cpu().detach().numpy())\n",
    "            obj[i, pos] = 1\n",
    "            \n",
    "        for i in range(y_train.size()[0]):\n",
    "            pos = np.argmax(y_train[i].cpu().detach().numpy())\n",
    "            no_obj[i, pos] = 0     \n",
    "        \n",
    "        loss_obj = mse_loss_adv(output[obj], y_train[obj])\n",
    "        loss_no_obj = mse_loss_adv(output[no_obj], y_train[no_obj])\n",
    "        loss_adv = 1.0 * loss_obj + 2.0 * loss_no_obj\n",
    "        \n",
    "        loss_adv.backward()\n",
    "        optimizer_adv.step()\n",
    "    \n",
    "    print('Loss', loss_adv.item())\n",
    "    \n",
    "    if loss_adv < best_loss_adv:\n",
    "        best_net_adv = copy.deepcopy(net_adv)\n",
    "        best_loss_adv = loss_adv\n",
    "\n",
    "time.sleep(0.1)\n",
    "print('Best loss', best_loss_adv.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(test) - 1)\n",
    "print('Item', i)\n",
    "\n",
    "net_result = best_net_adv(test[i][0].unsqueeze(0).to(TARGET))\n",
    "real = test[i][1]\n",
    "\n",
    "p = np.argmax(net_result.cpu().detach().numpy())\n",
    "r = np.argmax(real.detach().numpy())\n",
    "\n",
    "print('Predict:', LABELS[p])\n",
    "print('Real:', LABELS[r])\n",
    "\n",
    "img = np.array(test[i][0].permute(1, 2, 0))\n",
    "img = img[:, :, ::-1].copy()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(test) - 1)\n",
    "print('Item', i)\n",
    "\n",
    "net_result = best_net(test[i][0].unsqueeze(0).cuda())\n",
    "adv_net_result = best_net_adv(test[i][0].unsqueeze(0).cuda())\n",
    "real = test[i][1]\n",
    "\n",
    "p = np.argmax(net_result.cpu().detach().numpy())\n",
    "p_adv = np.argmax(adv_net_result.cpu().detach().numpy())\n",
    "r = np.argmax(real.detach().numpy())\n",
    "\n",
    "print('Predict', LABELS[p])\n",
    "print('Predict (adv loss)', LABELS[p_adv])\n",
    "print('Real', LABELS[r])\n",
    "\n",
    "img = np.array(test[i][0].permute(1, 2, 0))\n",
    "img = img[:, :, ::-1].copy()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of errors for every network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_wr = 0\n",
    "adv_net_wr = 0\n",
    "\n",
    "for t_data in tqdm(test):\n",
    "    net_result = best_net(t_data[0].unsqueeze(0).to(TARGET))\n",
    "    adv_net_result = best_net_adv(t_data[0].unsqueeze(0).to(TARGET))\n",
    "    \n",
    "    net_result = np.argmax(net_result.cpu().detach().numpy())\n",
    "    adv_net_result = np.argmax(adv_net_result.cpu().detach().numpy())\n",
    "    \n",
    "    real = np.argmax(t_data[1].cpu().detach().numpy())\n",
    "    \n",
    "    if net_result != real:\n",
    "        net_wr += 1\n",
    "    \n",
    "    if adv_net_result != real:\n",
    "        adv_net_wr += 1\n",
    "\n",
    "time.sleep(0.1)\n",
    "print('Predict errors', net_wr)\n",
    "print('Predict errors (adv loss)', adv_net_wr)\n",
    "\n",
    "print('Accuracy', (1 - float(net_wr / len(test))) * 100)\n",
    "print('Accuracy (adv loss)', (1 - float(adv_net_wr / len(test))) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_net.state_dict(), 'resnet18.pt')\n",
    "torch.save(best_net_adv.state_dict(), 'resnet18_adv_loss.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
